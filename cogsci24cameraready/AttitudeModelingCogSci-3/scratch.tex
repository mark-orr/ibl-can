The conceptual language of the CAN model literature has not been in terms of retrievals, but in terms of changes in attractor states under perturbation (e.g., fix a value of $\tau_i$ as we did for Study 2) or differences in attractor states given systematic differences in graph topology (e.g., larger values of the weights $w_{ij}$s or more a more dense set of weights $w_{ij}$s) \citep{dalege2016,DalegeMaas2017,DalegevanderMaas2020}. Although there is no technical difference between retrieval or perturbation in the CAN model, the use of perturbation captures a different semantic, one that is clear when you understand tht the CAN model literature stems from the psychological networks literature that originated in large part in clinical psychology.  The emphasis in psychologcial networks is on network properties and how network properties can predict changes in the network states. Thus, the language of perturbation is apt.  

However, the extension of this semantic to attitudinal memory models does not seem to work, as our preliminary results above show.        

The focus of the CAN model literature [put all refs] has been, to date, to make predictions about retrieval in reference to the graph topology.  For example, several papers explore the degree of change in retrievals given cues of vertices that are more or less central in the graph or degree of change in retrievals So, maybe this critique can be solved im future comparisons. 
   
Our The resulting graph has many excitatory connections with a small set, relatively of inhibitory negative weights. Thus, the lack of adaptability to cues shown in Study 2 is not surprising. The system captures correlations but when used in a dynamic associative memory network, the cuing did not work well in part because the model was not designed with sensible cuing in mind. The ACT-R model, by virtue of its grounding in a cogniitve architecture, inherited an adaptive adn reasonable cuing behavior.  Our final assessment is that, if the CAN model is to be viable, then it should move beyond an analysis of its network and think towards a sensible cuing system, in the name of external validity. 

Yet, in this literature, when using empirical graph generation techniques, the focus has not been on retrieval properties in relation to thd data but only in relation to other retrievals. For example, in 2017b the focus was on how much retrieval changed the retrieval distribution in comparison to central and noncentral nodes.  The differences found were not in relation to the actual data and thus claims about how well the model reflected what it learned was not addressed to any degree.  We think this is a weakness in the CAN literature.  

REF ALL THE CAN STUFF.